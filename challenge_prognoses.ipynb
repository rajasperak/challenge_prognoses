{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b429a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV,train_test_split,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,roc_curve,auc\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c55b4c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_stat_result(model, x_train, y_train, x_test, y_test,b_seuil_label=False):\n",
    "    train_predictions = model.predict(x_train.to_numpy())\n",
    "    test_predictions = model.predict(x_test.to_numpy())\n",
    "    if b_seuil_label==True:\n",
    "        train_predictions = (train_predictions>=0.5).astype(int)\n",
    "        test_predictions = (test_predictions>=0.5).astype(int)\n",
    "    print(\"test_predictions:\")\n",
    "    print(test_predictions)\n",
    "    cm = confusion_matrix(y_test, test_predictions)\n",
    "    print(cm)\n",
    "    print(\">> resultat de la classification:\")\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    TP = cm[0,0]\n",
    "    TN = cm[1,1]\n",
    "    FP = cm[0,1]\n",
    "    FN = cm[1,0]\n",
    "    classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "    print('Justesse de la Classification (accuracy) : {0:0.4f}'.format(classification_accuracy))\n",
    "    classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "    print('Erreurs de Classification : {0:0.4f}'.format(classification_error))\n",
    "    recall = TP / float(TP + FN)\n",
    "    print('Recall ou Sensitivity : {0:0.4f}'.format(recall))\n",
    "    print(\"taux de faux positive:\")\n",
    "    false_positive_rate = FP / float(FP + TN)\n",
    "    print(false_positive_rate)\n",
    "    print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))\n",
    "    specificity = TN / (TN + FP)\n",
    "    print('Specificity : {0:0.4f}'.format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57446dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>stiff_neck</th>\n",
       "      <th>irritability</th>\n",
       "      <th>confusion</th>\n",
       "      <th>tremor</th>\n",
       "      <th>paralysis</th>\n",
       "      <th>lymph_swells</th>\n",
       "      <th>lips_irritation</th>\n",
       "      <th>toenail_loss</th>\n",
       "      <th>speech_problem</th>\n",
       "      <th>bullseye_rash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain  \\\n",
       "0             0.0       0.0          0.0         0.0          0.0         0.0   \n",
       "1             1.0       1.0          0.0         1.0          0.0         1.0   \n",
       "2             1.0       1.0          0.0         1.0          1.0         1.0   \n",
       "3             0.0       1.0          0.0         0.0          0.0         1.0   \n",
       "4             0.0       0.0          1.0         0.0          1.0         1.0   \n",
       "..            ...       ...          ...         ...          ...         ...   \n",
       "298           0.0       1.0          0.0         0.0          0.0         0.0   \n",
       "299           1.0       0.0          1.0         0.0          1.0         1.0   \n",
       "300           1.0       0.0          0.0         1.0          1.0         0.0   \n",
       "301           1.0       0.0          1.0         1.0          1.0         0.0   \n",
       "302           1.0       0.0          0.0         0.0          0.0         0.0   \n",
       "\n",
       "     vomiting  rash  diarrhea  hypotension  ...  stiff_neck  irritability  \\\n",
       "0         0.0   0.0       0.0          1.0  ...         0.0           0.0   \n",
       "1         1.0   1.0       1.0          1.0  ...         0.0           0.0   \n",
       "2         1.0   0.0       1.0          0.0  ...         1.0           0.0   \n",
       "3         1.0   1.0       0.0          0.0  ...         0.0           0.0   \n",
       "4         0.0   0.0       1.0          1.0  ...         0.0           0.0   \n",
       "..        ...   ...       ...          ...  ...         ...           ...   \n",
       "298       0.0   0.0       1.0          0.0  ...         0.0           0.0   \n",
       "299       0.0   1.0       1.0          1.0  ...         0.0           0.0   \n",
       "300       1.0   1.0       1.0          1.0  ...         0.0           1.0   \n",
       "301       1.0   0.0       0.0          0.0  ...         0.0           0.0   \n",
       "302       1.0   0.0       1.0          0.0  ...         0.0           0.0   \n",
       "\n",
       "     confusion  tremor  paralysis  lymph_swells  lips_irritation  \\\n",
       "0          0.0     1.0        0.0           0.0              0.0   \n",
       "1          0.0     0.0        0.0           0.0              0.0   \n",
       "2          0.0     1.0        0.0           0.0              0.0   \n",
       "3          0.0     1.0        0.0           0.0              0.0   \n",
       "4          0.0     0.0        0.0           0.0              0.0   \n",
       "..         ...     ...        ...           ...              ...   \n",
       "298        0.0     0.0        0.0           0.0              0.0   \n",
       "299        0.0     0.0        0.0           0.0              0.0   \n",
       "300        1.0     1.0        1.0           1.0              1.0   \n",
       "301        0.0     1.0        0.0           0.0              0.0   \n",
       "302        0.0     0.0        0.0           0.0              0.0   \n",
       "\n",
       "     toenail_loss  speech_problem  bullseye_rash  \n",
       "0             0.0             0.0            0.0  \n",
       "1             0.0             0.0            0.0  \n",
       "2             0.0             0.0            0.0  \n",
       "3             0.0             0.0            0.0  \n",
       "4             0.0             0.0            0.0  \n",
       "..            ...             ...            ...  \n",
       "298           0.0             0.0            0.0  \n",
       "299           0.0             0.0            0.0  \n",
       "300           0.0             0.0            0.0  \n",
       "301           0.0             0.0            0.0  \n",
       "302           0.0             0.0            0.0  \n",
       "\n",
       "[303 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'C:\\Users\\karl\\Documents\\datasets\\playground23'\n",
    "df_train = pd.read_csv(\"df_train_new.csv\",sep=\";\")\n",
    "df_train = df_train.drop([\"Unnamed: 0\",\"id\"],axis=1)\n",
    "df_test = pd.read_csv(\"df_test_new.csv\",sep=\";\")\n",
    "df_test = df_test.drop([\"Unnamed: 0\",\"id\"],axis=1)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540070b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Malaria                  48\n",
       "Lyme_disease             52\n",
       "Plague                   53\n",
       "Zika                     58\n",
       "Yellow_Fever             61\n",
       "Dengue                   63\n",
       "Chikungunya              66\n",
       "Tungiasis                70\n",
       "Rift_Valley_fever        70\n",
       "Japanese_encephalitis    81\n",
       "West_Nile_fever          85\n",
       "Name: prognosis, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"prognosis\"].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c6b71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop([\"prognosis\"],axis=1)\n",
    "y = df_train['prognosis']\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=123,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "021f3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop([\"prognosis\"],axis=1)\n",
    "y = df_train['prognosis']\n",
    "x_train_,x_test_,y_train_,y_test_ = train_test_split(X,y,test_size=0.2,random_state=123,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e98a3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes encodées :  [ 0  7 10  2  2  7  0  0  8  2  8  1  4  2  5  4  5  6  2  2  4  5 10  3\n",
      "  2  5  2  7  1 10  6 10  7  1  7  2  4  5  0  8  7  8 10  4  9  8  7  5\n",
      "  2 10  8  2  6  5  1  7  1  9  6  5  0  4  1  3  7  3  4  1  8  2  4  2\n",
      "  8  3  7  6  5  0  4  6 10  5  1  3  3  0  7  3 10  9  9  9  9  1 10  6\n",
      "  1  6  8  9  1  0  8  0  7  6  2  6  4  8 10  7  7  1 10  0  3  8  8  5\n",
      "  1 10  8  1  5  9  9  8 10  8  4  9  3  2  8  1  9 10  6  2  3  2  2 10\n",
      "  5  8 10  6  7  1  4  0  6  3  0  9  5  2  1  3  9  1  0  5  7  7  6  9\n",
      "  2  7 10  3  2  7  3  6  9  6  1  4  7  8  7  9  7  7  2  1  2  2  7  6\n",
      "  7  5  7  2  9  8  2  3  0  6  5  1  8  4  0  0  4  3  7  3 10  4  6  6\n",
      "  1 10  8  8  6  3  7  0  7  5 10  4  7  3  8  2  8  8  2  8  6  0  6  7\n",
      "  6  2  2  4  8  3  3  3  2  2  0  8  9  6  0  6  5  5  8  5  2  8  3  7\n",
      "  9  8  0  2 10  9  5  6  8  7  4  2  8 10  0  9  9  8  4  8  2  9  8  3\n",
      "  0  4  9  2  2  1  3  4  6 10  0  2  3  2  6  2  2  9 10  7  4  6  0  9\n",
      "  8  0  2  1 10  7  1  3 10  7  1  1  1  0  8  6  5  8  4  1  8  6  2  2\n",
      "  1  0  3  5  8  3  2  2 10  8  8  4  0  2  8  6  0  6  7 10  8  9  9  5\n",
      "  9  9 10  7  9 10  0 10  5  7  4  6  6  9  9  7  7 10  6  9  4  3  0  1\n",
      " 10  3  9  9  6  8  8  8  4  2  9  1  6  8  0  0  6  6  4  6  0  5  5  6\n",
      " 10  9  2  6  0  9  8  6  6  8  1  3  7  1  7  0  6  2  8  4  5 10  5  6\n",
      "  3  5  1  2  6  0  3  2  9  5  5  0  4 10  4  0  2  7  7  6  5  7  3  7\n",
      "  8  4  2 10  8  1  9  8  3  9  8 10  2  2  4  5  1  6  7  1  2  8  8  2\n",
      "  2  1  0  5  0  8  3  1  8  8  3  8  6  0  2  7  7  3  5  0  1  3  5  7\n",
      "  1  1  6  8  2  6  3 10  1 10  1  2  4  9 10 10  6  7  5  8  1  1  8  5\n",
      "  9  3  2  8  1  0 10  4  6  0  0  2 10  5  4  0  7  0  1  9  7  7  1 10\n",
      " 10  9  9  4  8  0  0  0  7  0  9  5  9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Créer une instance de LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convertir les classes de chaînes de caractères en entiers\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Afficher les classes encodées\n",
    "print(\"Classes encodées : \", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ef5f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = x_train.copy()\n",
    "y_train_1 = y_train.copy()\n",
    "x_test_1 = x_test.copy()\n",
    "y_test_1 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d13f50e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_predictions:\n",
      "[8 3 3 2 2 7 2 2 2 0 0 8 7 0 2 0 3 3 7 8 1 8 3 2 2 8 0 8 3 0 3 2 8 2 2 7 0\n",
      " 3 1 8 9 3 0 8 3 3 0 2 3 7 8 2 2 3 7 7 2 8 2 8 0 7 8 0 3 8 7 8 2 8 7 2 8 7\n",
      " 8 3 2 7 1 0 3 2 3 0 3 8 0 3 3 8 0 8 3 1 7 0 8 0 3 8 8 8 3 2 2 8 2 3 7 0 2\n",
      " 7 7 8 7 3 2 8 2 3 0 7 2 8 3 8 8 7 0 3 0 0 3 0 0 2 3 9 8 3 8 2]\n",
      "[[10  0  2  0  0  0  0  0  1  0  0]\n",
      " [ 2  0  1  3  0  0  0  3  4  0  0]\n",
      " [ 4  1  1  5  0  0  0  1  3  1  0]\n",
      " [ 0  0  0  8  0  0  0  1  1  0  0]\n",
      " [ 1  0  1  4  0  0  0  0  4  0  0]\n",
      " [ 0  0  4  4  0  0  0  1  2  0  0]\n",
      " [ 3  1  3  1  0  0  0  1  5  0  0]\n",
      " [ 0  2  3  0  0  0  0  9  0  0  0]\n",
      " [ 2  0  2  4  0  0  0  3  6  0  0]\n",
      " [ 2  0  8  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  4  2  0  0  0  0  5  1  0]]\n",
      ">> resultat de la classification:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.77      0.54        13\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.03      0.06      0.04        16\n",
      "           3       0.26      0.80      0.39        10\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.00      0.00      0.00        11\n",
      "           6       0.00      0.00      0.00        14\n",
      "           7       0.47      0.64      0.55        14\n",
      "           8       0.18      0.35      0.24        17\n",
      "           9       0.00      0.00      0.00        12\n",
      "          10       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.24       142\n",
      "   macro avg       0.12      0.24      0.16       142\n",
      "weighted avg       0.13      0.24      0.16       142\n",
      "\n",
      "Justesse de la Classification (accuracy) : 0.8333\n",
      "Erreurs de Classification : 0.1667\n",
      "Recall ou Sensitivity : 0.8333\n",
      "taux de faux positive:\n",
      "nan\n",
      "False Positive Rate : nan\n",
      "Specificity : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\karl\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\karl\\AppData\\Local\\Temp\\ipykernel_6116\\1149329073.py:24: RuntimeWarning: invalid value encountered in divide\n",
      "  false_positive_rate = FP / float(FP + TN)\n",
      "C:\\Users\\karl\\AppData\\Local\\Temp\\ipykernel_6116\\1149329073.py:27: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  specificity = TN / (TN + FP)\n"
     ]
    }
   ],
   "source": [
    "ovr = OneVsRestClassifier(LogisticRegression(solver=\"saga\",penalty='l1',C=0.1))\n",
    "ovr.fit(x_train_1,y_train_1)\n",
    "one_stat_result(ovr, x_train_1, y_train_1, x_test_1, y_test_1,b_seuil_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d4d9cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 = x_train.copy()\n",
    "y_train_2 = y_train.copy()\n",
    "x_test_2 = x_test.copy()\n",
    "y_test_2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2ed1b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_label = len(set(list(y_train_2)))\n",
    "nb_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60487b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 100,\n",
       " 'num_class': 11,\n",
       " 'objective': 'multi:softmax',\n",
       " 'reg_lambda': 0.5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': list(range(2,6,1)),\n",
    "    'learning_rate': [0.2,0.1,0.01,0.001],\n",
    "    'n_estimators': [50,100,300,400],\n",
    "    'reg_lambda': [0.5,0.1],\n",
    "    'objective': ['multi:softmax'],\n",
    "    'num_class': [nb_label], # Remplacez num_classes par le nombre de classes dans votre ensemble de données\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(x_train_2, y_train_2)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ae8cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_stat_result(model, x_train, y_train, x_test, y_test,b_seuil_label=False):\n",
    "    train_predictions = model.predict(x_train)\n",
    "    test_predictions = model.predict(x_test)\n",
    "    if b_seuil_label==True:\n",
    "        train_predictions = (train_predictions>=0.5).astype(int)\n",
    "        test_predictions = (test_predictions>=0.5).astype(int)\n",
    "    print(\"test_predictions:\")\n",
    "    print(test_predictions)\n",
    "    cm = confusion_matrix(y_test, test_predictions)\n",
    "    print(cm)\n",
    "    print(\">> resultat de la classification:\")\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    TP = cm[0,0]\n",
    "    TN = cm[1,1]\n",
    "    FP = cm[0,1]\n",
    "    FN = cm[1,0]\n",
    "    classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "    print('Justesse de la Classification (accuracy) : {0:0.4f}'.format(classification_accuracy))\n",
    "    classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "    print('Erreurs de Classification : {0:0.4f}'.format(classification_error))\n",
    "    recall = TP / float(TP + FN)\n",
    "    print('Recall ou Sensitivity : {0:0.4f}'.format(recall))\n",
    "    print(\"taux de faux positive:\")\n",
    "    false_positive_rate = FP / float(FP + TN)\n",
    "    print(false_positive_rate)\n",
    "    print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))\n",
    "    specificity = TN / (TN + FP)\n",
    "    print('Specificity : {0:0.4f}'.format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27f8b5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_class=11,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_class=11,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_class=11,\n",
       "              num_parallel_tree=None, objective='multi:softmax', ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba483914",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2524e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_3 = x_train.copy()\n",
    "y_train_3 = y_train.copy()\n",
    "x_test_3 = x_test.copy()\n",
    "y_test_3 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de9b815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_class=11,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_class=11,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_class=11,\n",
       "              num_parallel_tree=None, objective='multi:softmax', ...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb.fit(x_train_3.values,y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f2eeb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_predictions:\n",
      "[10  3  3  2  2  1  2  8  7  6  0  3  3  0  2  1  2  2  3 10  6 10  2  9\n",
      "  2  8  0  4  3  6  3  6  4  5  2  7  8  3  8  9  9  8  0  4  3  8  0 10\n",
      "  8  7  5  0  9  4  1  7  2  8 10  8  6  3  8  0  3  9  7  3 10  1  7  4\n",
      "  9  7  1  3  9  8  1  9  8  9  3  0  3  8  0  3  5  9  2  8  6  8  7  0\n",
      "  2  0  3  4  8  8  4  4  9  9  2  5  5  8  9  7  7  8  8  3  5  1  2  2\n",
      "  0  7  2  8  4  6  9  3  0  2  6  1 10  0  6 10  3 10  4  2  6 10]\n",
      "[[10  1  1  0  0  0  1  0  0  0  0]\n",
      " [ 2  1  1  1  2  0  0  3  3  0  0]\n",
      " [ 0  1  3  2  0  0  3  0  3  3  1]\n",
      " [ 0  0  0  6  1  2  0  0  1  0  0]\n",
      " [ 0  1  2  3  2  0  0  0  1  1  0]\n",
      " [ 0  0  3  5  1  0  0  0  0  1  1]\n",
      " [ 1  2  2  0  0  0  2  1  2  2  2]\n",
      " [ 0  1  1  0  0  1  1  7  2  0  1]\n",
      " [ 0  1  1  3  1  2  1  0  5  1  2]\n",
      " [ 1  0  2  0  2  1  0  0  1  4  1]\n",
      " [ 0  0  2  0  1  0  2  0  3  2  2]]\n",
      ">> resultat de la classification:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74        13\n",
      "           1       0.12      0.08      0.10        13\n",
      "           2       0.17      0.19      0.18        16\n",
      "           3       0.30      0.60      0.40        10\n",
      "           4       0.20      0.20      0.20        10\n",
      "           5       0.00      0.00      0.00        11\n",
      "           6       0.20      0.14      0.17        14\n",
      "           7       0.64      0.50      0.56        14\n",
      "           8       0.24      0.29      0.26        17\n",
      "           9       0.29      0.33      0.31        12\n",
      "          10       0.20      0.17      0.18        12\n",
      "\n",
      "    accuracy                           0.30       142\n",
      "   macro avg       0.28      0.30      0.28       142\n",
      "weighted avg       0.28      0.30      0.28       142\n",
      "\n",
      "Justesse de la Classification (accuracy) : 0.7857\n",
      "Erreurs de Classification : 0.2143\n",
      "Recall ou Sensitivity : 0.8333\n",
      "taux de faux positive:\n",
      "0.5\n",
      "False Positive Rate : 0.5000\n",
      "Specificity : 0.5000\n"
     ]
    }
   ],
   "source": [
    "one_stat_result(best_xgb, x_train_3, y_train_3, x_test_3, y_test_3,b_seuil_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dccd43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On va essayer de reduire la dimensionalité des données avec une ACP  vu la nature des données, avant de les données aux modèles: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fd850d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05060698,  1.59002884, -0.08955948, ..., -1.02375527,\n",
       "         0.58219131,  0.77722016],\n",
       "       [ 1.45759549,  0.18444175,  0.29842092, ..., -0.80829271,\n",
       "         0.6516778 , -0.49837549],\n",
       "       [ 3.94532304, -0.57006168,  0.21993827, ...,  0.51929663,\n",
       "        -0.97645519, -0.69114091],\n",
       "       ...,\n",
       "       [ 1.12354428, -0.68442848,  0.24858868, ..., -0.70072378,\n",
       "         0.35607482, -0.86055038],\n",
       "       [ 0.82167578, -1.42965125,  1.26132215, ..., -0.176359  ,\n",
       "        -0.07159885,  0.99064066],\n",
       "       [-0.49901745,  1.70641893,  0.25321675, ...,  1.23224151,\n",
       "        -0.07956164,  0.06521126]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "acp = PCA(n_components=8) # d'apres le pca réalisé dans le fichier preprocessing\n",
    "x_train_pca = acp.fit_transform(x_train)\n",
    "x_train_pca\n",
    "x_test_pca = acp.transform(x_test)\n",
    "x_test_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7f8230a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pca = xgb.XGBClassifier(learning_rate= 0.1,max_depth= 3,\n",
    " n_estimators= 100,\n",
    " num_class= 11,\n",
    " objective= 'multi:softmax',\n",
    " reg_lambda= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "058e3d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_class=11,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_class=11,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_class=11,\n",
       "              num_parallel_tree=None, objective='multi:softmax', ...)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pca.fit(x_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2f0b4eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_predictions:\n",
      "[ 8  8  3 10  4  7  9  6  7  2  0  3  3  0  4  1  8  4  3  5  6  8  8 10\n",
      "  6  8  0  5  4  6  4  2  6  2  2  0  2  3  6  5 10  9  1  4  3  5  0  9\n",
      "  8  7  6  8  2  8  2  7  7  4  6  6  6  8  1  1  5  2  6  9  2  1  7  5\n",
      "  8  7  1  3 10  0  6  6  3 10  3  0  3  8  0  4 10  9  2  6  8  1  7  0\n",
      "  9  0  3  4 10  5  4  8  9 10 10  5  8  2  2  7  1  8  0  3  4  6  2  3\n",
      "  0  0  2  8  3  8  9  3  0  3  7  1  9  1  8  8  3  2  4  8  3 10]\n",
      "[[8 1 0 0 0 0 2 0 2 0 0]\n",
      " [2 2 0 0 0 1 1 3 4 0 0]\n",
      " [0 0 3 3 1 0 4 0 3 1 1]\n",
      " [0 0 0 4 1 2 1 0 1 0 1]\n",
      " [0 2 0 2 3 0 1 0 0 1 1]\n",
      " [0 0 3 5 2 0 0 0 1 0 0]\n",
      " [1 1 1 0 0 0 2 2 3 2 2]\n",
      " [2 2 0 0 0 0 3 5 1 0 1]\n",
      " [1 1 3 3 2 3 1 0 2 1 0]\n",
      " [0 1 2 0 2 1 0 0 2 2 2]\n",
      " [0 0 3 1 1 1 0 0 2 2 2]]\n",
      ">> resultat de la classification:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.59        13\n",
      "           1       0.20      0.15      0.17        13\n",
      "           2       0.20      0.19      0.19        16\n",
      "           3       0.22      0.40      0.29        10\n",
      "           4       0.25      0.30      0.27        10\n",
      "           5       0.00      0.00      0.00        11\n",
      "           6       0.13      0.14      0.14        14\n",
      "           7       0.50      0.36      0.42        14\n",
      "           8       0.10      0.12      0.11        17\n",
      "           9       0.22      0.17      0.19        12\n",
      "          10       0.20      0.17      0.18        12\n",
      "\n",
      "    accuracy                           0.23       142\n",
      "   macro avg       0.24      0.24      0.23       142\n",
      "weighted avg       0.24      0.23      0.23       142\n",
      "\n",
      "Justesse de la Classification (accuracy) : 0.7692\n",
      "Erreurs de Classification : 0.2308\n",
      "Recall ou Sensitivity : 0.8000\n",
      "taux de faux positive:\n",
      "0.3333333333333333\n",
      "False Positive Rate : 0.3333\n",
      "Specificity : 0.6667\n"
     ]
    }
   ],
   "source": [
    "one_stat_result(xgb_pca, x_train_pca, y_train_3, x_test_pca, y_test_3,b_seuil_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "60e168b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n",
      "57/57 [==============================] - 1s 2ms/step - loss: 2.3736 - accuracy: 0.1504\n",
      "Epoch 2/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 2.2202 - accuracy: 0.2584\n",
      "Epoch 3/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 2.0898 - accuracy: 0.3168\n",
      "Epoch 4/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.9710 - accuracy: 0.3522\n",
      "Epoch 5/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.8853 - accuracy: 0.3540\n",
      "Epoch 6/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.8055 - accuracy: 0.3858\n",
      "Epoch 7/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.7419 - accuracy: 0.3965\n",
      "Epoch 8/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.6636 - accuracy: 0.4265\n",
      "Epoch 9/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.6091 - accuracy: 0.4460\n",
      "Epoch 10/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.5383 - accuracy: 0.4938\n",
      "Epoch 11/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.4739 - accuracy: 0.5274\n",
      "Epoch 12/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.4194 - accuracy: 0.5239\n",
      "Epoch 13/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.3543 - accuracy: 0.5611\n",
      "Epoch 14/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.3074 - accuracy: 0.5841\n",
      "Epoch 15/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.2585 - accuracy: 0.6053\n",
      "Epoch 16/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.2071 - accuracy: 0.6088\n",
      "Epoch 17/48\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.1536 - accuracy: 0.6407\n",
      "Epoch 18/48\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.1013 - accuracy: 0.6513\n",
      "Epoch 19/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.0636 - accuracy: 0.6779\n",
      "Epoch 20/48\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.0194 - accuracy: 0.6885\n",
      "Epoch 21/48\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.9761 - accuracy: 0.7133\n",
      "Epoch 22/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.9355 - accuracy: 0.7292\n",
      "Epoch 23/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8961 - accuracy: 0.7310\n",
      "Epoch 24/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8542 - accuracy: 0.7522\n",
      "Epoch 25/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8250 - accuracy: 0.7664\n",
      "Epoch 26/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7879 - accuracy: 0.7805\n",
      "Epoch 27/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7503 - accuracy: 0.8000\n",
      "Epoch 28/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7222 - accuracy: 0.8053\n",
      "Epoch 29/48\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.8230\n",
      "Epoch 30/48\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.8407\n",
      "Epoch 31/48\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.8496\n",
      "Epoch 32/48\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.8673\n",
      "Epoch 33/48\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.8549\n",
      "Epoch 34/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.8637\n",
      "Epoch 35/48\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.8690\n",
      "Epoch 36/48\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.8867\n",
      "Epoch 37/48\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.8973\n",
      "Epoch 38/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.9080\n",
      "Epoch 39/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.9221\n",
      "Epoch 40/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.9168\n",
      "Epoch 41/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.9292\n",
      "Epoch 42/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.9327\n",
      "Epoch 43/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.9416\n",
      "Epoch 44/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.9416\n",
      "Epoch 45/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.9434\n",
      "Epoch 46/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.9540\n",
      "Epoch 47/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.9575\n",
      "Epoch 48/48\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.9646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204e180ed90>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pour le model rna:\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "#classifier.load_weights(filepath=path_out+'\\best_rna_model_churn.hdf5')\n",
    "y_train_cat = to_categorical(y_train, num_classes=11)\n",
    "y_test_cat = to_categorical(y_test, num_classes=11)\n",
    "# Créer un nouveau modèle avec les mêmes couches et paramètres que le modèle original\n",
    "best_model = Sequential()\n",
    "best_model.add(Dense(units=50,kernel_initializer=\"glorot_uniform\",activation='relu',input_dim=x_train.shape[1]))\n",
    "best_model.add(Dense(units=40,kernel_initializer=\"glorot_uniform\",activation='relu'))\n",
    "best_model.add(Dense(units=11,kernel_initializer=\"glorot_uniform\",activation='softmax'))\n",
    "best_model.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
    "# Charger les poids du meilleur modèle dans le nouveau modèle\n",
    "best_model.fit(x_train_, y_train_cat,batch_size=10,epochs=48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "70f42eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Faire des prédictions avec les données de test\n",
    "y_pred = best_model.predict(x_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d91e9d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les prédictions en format catégoriel en utilisant argmax\n",
    "y_pred_cat = np.argmax(y_pred, axis=1)\n",
    "# Convertir les étiquettes de classe catégorielles en format continu en utilisant argmax\n",
    "y_test_cat = np.argmax(y_test_cat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fed9cc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  2  0  0  0  1  0  0  0  0]\n",
      " [ 2  2  1  0  1  1  1  3  2  0  0]\n",
      " [ 1  0  4  3  0  0  1  2  2  2  1]\n",
      " [ 0  0  0  5  0  2  0  0  2  0  1]\n",
      " [ 0  0  2  2  1  0  0  1  1  3  0]\n",
      " [ 0  0  2  2  1  3  0  0  1  1  1]\n",
      " [ 2  1  2  0  0  2  1  1  1  1  3]\n",
      " [ 0  1  2  0  0  0  1  5  3  1  1]\n",
      " [ 1  1  2  3  0  0  1  0  4  3  2]\n",
      " [ 1  0  1  0  1  1  2  1  1  2  2]\n",
      " [ 0  0  2  0  1  0  1  2  4  1  1]]\n"
     ]
    }
   ],
   "source": [
    "# Calculer la matrice de confusion\n",
    "cm = confusion_matrix(y_test_cat, y_pred_cat)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e7e4d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def classification_performance(cm):\n",
    "    # Calculer la précision, le rappel et le score F1 pour chaque classe\n",
    "    precision = np.diag(cm) / np.sum(cm, axis=0)\n",
    "    recall = np.diag(cm) / np.sum(cm, axis=1)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    # Calculer la précision moyenne et le score F1 pondéré\n",
    "    precision_macro = np.mean(precision)\n",
    "    f1_weighted = np.sum(f1 * np.sum(cm, axis=1)) / np.sum(cm)\n",
    "    \n",
    "    # Afficher les performances de classification pour chaque classe et la précision moyenne et le score F1 pondéré\n",
    "    for i in range(len(precision)):\n",
    "        print(\"Classe {}: Precision = {:.4f}, Recall = {:.4f}, F1 = {:.4f}\".format(i, precision[i], recall[i], f1[i]))\n",
    "    \n",
    "    print(\"Precision moyenne: {:.4f}\".format(precision_macro))\n",
    "    print(\"Score F1 pondéré: {:.4f}\".format(f1_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "765d844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe 0: Precision = 0.5882, Recall = 0.7692, F1 = 0.6667\n",
      "Classe 1: Precision = 0.4000, Recall = 0.1538, F1 = 0.2222\n",
      "Classe 2: Precision = 0.2000, Recall = 0.2500, F1 = 0.2222\n",
      "Classe 3: Precision = 0.3333, Recall = 0.5000, F1 = 0.4000\n",
      "Classe 4: Precision = 0.2000, Recall = 0.1000, F1 = 0.1333\n",
      "Classe 5: Precision = 0.3333, Recall = 0.2727, F1 = 0.3000\n",
      "Classe 6: Precision = 0.1111, Recall = 0.0714, F1 = 0.0870\n",
      "Classe 7: Precision = 0.3333, Recall = 0.3571, F1 = 0.3448\n",
      "Classe 8: Precision = 0.1905, Recall = 0.2353, F1 = 0.2105\n",
      "Classe 9: Precision = 0.1429, Recall = 0.1667, F1 = 0.1538\n",
      "Classe 10: Precision = 0.0833, Recall = 0.0833, F1 = 0.0833\n",
      "Precision moyenne: 0.2651\n",
      "Score F1 pondéré: 0.2550\n"
     ]
    }
   ],
   "source": [
    "classification_performance(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ab30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "eclipse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
